{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp\n",
    "import pandas as pd\n",
    "from kfp import dsl\n",
    "from kfp.components import InputPath, OutputPath\n",
    "from kfp.components import create_component_from_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to load kube config.\n"
     ]
    },
    {
     "ename": "MaxRetryError",
     "evalue": "HTTPConnectionPool(host='localhost', port=80): Max retries exceeded with url: /apis/v1beta1/healthz (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001CC102B6288>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it'))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\envs\\kubeflow\\lib\\site-packages\\urllib3\\connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    174\u001b[0m             conn = connection.create_connection(\n\u001b[1;32m--> 175\u001b[1;33m                 \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dns_host\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mport\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mextra_kw\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    176\u001b[0m             )\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\kubeflow\\lib\\site-packages\\urllib3\\util\\connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[0;32m     94\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0merr\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 95\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     96\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\kubeflow\\lib\\site-packages\\urllib3\\util\\connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[0;32m     84\u001b[0m                 \u001b[0msock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource_address\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 85\u001b[1;33m             \u001b[0msock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msa\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msock\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mConnectionRefusedError\u001b[0m: [WinError 10061] No connection could be made because the target machine actively refused it",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\envs\\kubeflow\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    709\u001b[0m                 \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 710\u001b[1;33m                 \u001b[0mchunked\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mchunked\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    711\u001b[0m             )\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\kubeflow\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    397\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 398\u001b[1;33m                 \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mhttplib_request_kw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    399\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\kubeflow\\lib\\site-packages\\urllib3\\connection.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, body, headers)\u001b[0m\n\u001b[0;32m    238\u001b[0m             \u001b[0mheaders\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"User-Agent\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_default_user_agent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 239\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mHTTPConnection\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\kubeflow\\lib\\http\\client.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1280\u001b[0m         \u001b[1;34m\"\"\"Send a complete request to the server.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1281\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_send_request\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1282\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\kubeflow\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_send_request\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1326\u001b[0m             \u001b[0mbody\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'body'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1327\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mendheaders\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1328\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\kubeflow\\lib\\http\\client.py\u001b[0m in \u001b[0;36mendheaders\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1275\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mCannotSendHeader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1276\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_send_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage_body\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1277\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\kubeflow\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_send_output\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1035\u001b[0m         \u001b[1;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1036\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1037\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\kubeflow\\lib\\http\\client.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    975\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_open\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 976\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    977\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\kubeflow\\lib\\site-packages\\urllib3\\connection.py\u001b[0m in \u001b[0;36mconnect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 205\u001b[1;33m         \u001b[0mconn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_new_conn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    206\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_prepare_conn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\kubeflow\\lib\\site-packages\\urllib3\\connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    186\u001b[0m             raise NewConnectionError(\n\u001b[1;32m--> 187\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Failed to establish a new connection: %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    188\u001b[0m             )\n",
      "\u001b[1;31mNewConnectionError\u001b[0m: <urllib3.connection.HTTPConnection object at 0x000001CC102B6288>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-2ede2bcf3e53>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mclient\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mClient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mBASE_IMG\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"python:3.7\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\kubeflow\\lib\\site-packages\\kfp\\_client.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, host, client_id, namespace, other_client_id, other_client_secret, existing_token, cookies, proxy, ssl_ca_cert, kube_context, credentials, ui_host)\u001b[0m\n\u001b[0;32m    195\u001b[0m         self._healthz_api = kfp_server_api.api.healthz_service_api.HealthzServiceApi(\n\u001b[0;32m    196\u001b[0m             api_client)\n\u001b[1;32m--> 197\u001b[1;33m         if not self._context_setting['namespace'] and self.get_kfp_healthz(\n\u001b[0m\u001b[0;32m    198\u001b[0m         ).multi_user is True:\n\u001b[0;32m    199\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\kubeflow\\lib\\site-packages\\kfp\\_client.py\u001b[0m in \u001b[0;36mget_kfp_healthz\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    409\u001b[0m                         max_attempts))\n\u001b[0;32m    410\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 411\u001b[1;33m                 \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_healthz_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_healthz\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    412\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    413\u001b[0m             \u001b[1;31m# ApiException, including network errors, is the only type that may\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\kubeflow\\lib\\site-packages\\kfp_server_api\\api\\healthz_service_api.py\u001b[0m in \u001b[0;36mget_healthz\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m         \"\"\"\n\u001b[0;32m     62\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'_return_http_data_only'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_healthz_with_http_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# noqa: E501\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_healthz_with_http_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# noqa: E501\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\kubeflow\\lib\\site-packages\\kfp_server_api\\api\\healthz_service_api.py\u001b[0m in \u001b[0;36mget_healthz_with_http_info\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    146\u001b[0m             \u001b[0m_preload_content\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlocal_var_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'_preload_content'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m             \u001b[0m_request_timeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlocal_var_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'_request_timeout'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 148\u001b[1;33m             collection_formats=collection_formats)\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\kubeflow\\lib\\site-packages\\kfp_server_api\\api_client.py\u001b[0m in \u001b[0;36mcall_api\u001b[1;34m(self, resource_path, method, path_params, query_params, header_params, body, post_params, files, response_type, auth_settings, async_req, _return_http_data_only, collection_formats, _preload_content, _request_timeout, _host)\u001b[0m\n\u001b[0;32m    367\u001b[0m                                    \u001b[0mresponse_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mauth_settings\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    368\u001b[0m                                    \u001b[0m_return_http_data_only\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcollection_formats\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 369\u001b[1;33m                                    _preload_content, _request_timeout, _host)\n\u001b[0m\u001b[0;32m    370\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    371\u001b[0m         return self.pool.apply_async(self.__call_api, (resource_path,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\kubeflow\\lib\\site-packages\\kfp_server_api\\api_client.py\u001b[0m in \u001b[0;36m__call_api\u001b[1;34m(self, resource_path, method, path_params, query_params, header_params, body, post_params, files, response_type, auth_settings, _return_http_data_only, collection_formats, _preload_content, _request_timeout, _host)\u001b[0m\n\u001b[0;32m    183\u001b[0m                 \u001b[0mpost_params\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpost_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m                 \u001b[0m_preload_content\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_preload_content\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 185\u001b[1;33m                 _request_timeout=_request_timeout)\n\u001b[0m\u001b[0;32m    186\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mApiException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m             \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbody\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPY3\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\kubeflow\\lib\\site-packages\\kfp_server_api\\api_client.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, query_params, headers, post_params, body, _preload_content, _request_timeout)\u001b[0m\n\u001b[0;32m    391\u001b[0m                                         \u001b[0m_preload_content\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_preload_content\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    392\u001b[0m                                         \u001b[0m_request_timeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_request_timeout\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 393\u001b[1;33m                                         headers=headers)\n\u001b[0m\u001b[0;32m    394\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"HEAD\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    395\u001b[0m             return self.rest_client.HEAD(url,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\kubeflow\\lib\\site-packages\\kfp_server_api\\rest.py\u001b[0m in \u001b[0;36mGET\u001b[1;34m(self, url, headers, query_params, _preload_content, _request_timeout)\u001b[0m\n\u001b[0;32m    232\u001b[0m                             \u001b[0m_preload_content\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_preload_content\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m                             \u001b[0m_request_timeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_request_timeout\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 234\u001b[1;33m                             query_params=query_params)\n\u001b[0m\u001b[0;32m    235\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    236\u001b[0m     def HEAD(self, url, headers=None, query_params=None, _preload_content=True,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\kubeflow\\lib\\site-packages\\kfp_server_api\\rest.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, query_params, headers, body, post_params, _preload_content, _request_timeout)\u001b[0m\n\u001b[0;32m    210\u001b[0m                                               \u001b[0mpreload_content\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_preload_content\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m                                               \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 212\u001b[1;33m                                               headers=headers)\n\u001b[0m\u001b[0;32m    213\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0murllib3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSSLError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"{0}\\n{1}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\kubeflow\\lib\\site-packages\\urllib3\\request.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, fields, headers, **urlopen_kw)\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_encode_url_methods\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m             return self.request_encode_url(\n\u001b[1;32m---> 75\u001b[1;33m                 \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfields\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfields\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0murlopen_kw\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m             )\n\u001b[0;32m     77\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\kubeflow\\lib\\site-packages\\urllib3\\request.py\u001b[0m in \u001b[0;36mrequest_encode_url\u001b[1;34m(self, method, url, fields, headers, **urlopen_kw)\u001b[0m\n\u001b[0;32m     94\u001b[0m             \u001b[0murl\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;34m\"?\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0murlencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfields\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mextra_kw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m     def request_encode_body(\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\kubeflow\\lib\\site-packages\\urllib3\\poolmanager.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, redirect, **kw)\u001b[0m\n\u001b[0;32m    373\u001b[0m             \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    374\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 375\u001b[1;33m             \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mu\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest_uri\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    376\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    377\u001b[0m         \u001b[0mredirect_location\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mredirect\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_redirect_location\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\kubeflow\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    824\u001b[0m                 \u001b[0mchunked\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mchunked\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    825\u001b[0m                 \u001b[0mbody_pos\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbody_pos\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 826\u001b[1;33m                 \u001b[1;33m**\u001b[0m\u001b[0mresponse_kw\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    827\u001b[0m             )\n\u001b[0;32m    828\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\kubeflow\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    824\u001b[0m                 \u001b[0mchunked\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mchunked\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    825\u001b[0m                 \u001b[0mbody_pos\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbody_pos\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 826\u001b[1;33m                 \u001b[1;33m**\u001b[0m\u001b[0mresponse_kw\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    827\u001b[0m             )\n\u001b[0;32m    828\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\kubeflow\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    824\u001b[0m                 \u001b[0mchunked\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mchunked\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    825\u001b[0m                 \u001b[0mbody_pos\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbody_pos\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 826\u001b[1;33m                 \u001b[1;33m**\u001b[0m\u001b[0mresponse_kw\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    827\u001b[0m             )\n\u001b[0;32m    828\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\kubeflow\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    784\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    785\u001b[0m             retries = retries.increment(\n\u001b[1;32m--> 786\u001b[1;33m                 \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_pool\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_stacktrace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    787\u001b[0m             )\n\u001b[0;32m    788\u001b[0m             \u001b[0mretries\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\kubeflow\\lib\\site-packages\\urllib3\\util\\retry.py\u001b[0m in \u001b[0;36mincrement\u001b[1;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[0;32m    590\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    591\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnew_retry\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_exhausted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 592\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mMaxRetryError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_pool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merror\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mResponseError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcause\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    593\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    594\u001b[0m         \u001b[0mlog\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Incremented Retry for (url='%s'): %r\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_retry\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMaxRetryError\u001b[0m: HTTPConnectionPool(host='localhost', port=80): Max retries exceeded with url: /apis/v1beta1/healthz (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001CC102B6288>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it'))"
     ]
    }
   ],
   "source": [
    "client = kfp.Client()\n",
    "BASE_IMG = \"python:3.7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_logger():\n",
    "    \"\"\"\n",
    "    Custom Logger to debug, log the information, warnings and exceptions\n",
    "        :return: logger object with both file and stream handlers.\n",
    "\n",
    "    \"\"\"\n",
    "    if not utils_tools.path_exists(config.OUTPUT_LOG):\n",
    "        os.makedirs(config.OUTPUT_LOG)\n",
    "    log_file = datetime.now().strftime(\"execution_%H-%M-%d-%m-%Y.log\")\n",
    "    logger = logging.getLogger()\n",
    "    if not logger.hasHandlers():\n",
    "        logger = logging.getLogger()\n",
    "        logger.setLevel(logging.DEBUG)\n",
    "        formatter = logging.Formatter(\n",
    "            \"%(asctime)s: %(filename)s: %(funcName)s: %(lineno)d: %(message)s\"\n",
    "        )\n",
    "        file_handler = logging.FileHandler(os.path.join(config.OUTPUT_LOG, log_file))\n",
    "        file_handler.setFormatter(formatter)\n",
    "        stream_handler = logging.StreamHandler()\n",
    "        logger.addHandler(file_handler)\n",
    "        logger.addHandler(stream_handler)\n",
    "    return logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(**kwargs):\n",
    "    model = kwargs.get(\"model\")\n",
    "    num_epochs = kwargs.get(\"num_epochs\")\n",
    "    save_model = kwargs.get(\"save_model\")\n",
    "    train_dataloader = kwargs.get(\"train_dataloader\")\n",
    "    try:\n",
    "        self.model.to(\n",
    "            self.device\n",
    "        )  # To move the model parameters to the available device.\n",
    "        self.model.train()  # Call the train method from the nn.Module base class\n",
    "        self.logger.debug(\"Starting the Training Loop ..\")  # Training loop start\n",
    "        for epoch in range(num_epochs):\n",
    "            train_loss = 0\n",
    "            train_accuracy = 0\n",
    "            self.logger.debug(f\"[INFO] Epoch {epoch + 1} Started..\")\n",
    "            for index, batch in tqdm(enumerate(self.train_data_loader)):\n",
    "                self.logger.debug(\n",
    "                    f\"[INFO] [TRAINING] Epoch {epoch + 1} Iteration {index + 1} Running..\"\n",
    "                )\n",
    "                self.optimizer.zero_grad()\n",
    "                images = batch[\"image\"].to(self.device)\n",
    "                labels = batch[\"label\"].to(self.device)\n",
    "                outputs = self.model(inputs=images)\n",
    "                loss = self.loss_function(outputs, labels)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                train_loss = train_loss + loss.item()\n",
    "                _, hypothesis = torch.max(outputs, dim=1)\n",
    "                train_accuracy = (\n",
    "                    train_accuracy\n",
    "                    + torch.sum(torch.tensor(hypothesis == labels)).item()\n",
    "                )\n",
    "            train_accuracy = train_accuracy / (\n",
    "                len(self.train_data_loader) * config.TRAIN_BATCH_SIZE\n",
    "            )\n",
    "            train_loss = train_loss / (\n",
    "                len(self.train_data_loader) * config.TRAIN_BATCH_SIZE\n",
    "            )\n",
    "            train_st = (\n",
    "                f\"Training Loss: {train_loss} Train Accuracy: {train_accuracy}\"\n",
    "            )\n",
    "            self.logger.debug(f\"Epoch: {epoch} {train_st}\")\n",
    "        if self.save_model:\n",
    "            utils_tools.save_model(model_name=config.IMAGE_CLASSIFIER, model=self.model)\n",
    "    except (RuntimeError, MemoryError, ValueError, TypeError):\n",
    "        self.logger.exception(\"Training Exception Occurred\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    class Test:\n",
    "        def __init__(self):\n",
    "            self.a = 10\n",
    "    obj = Test()\n",
    "    print(obj.a)\n",
    "    return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to load kube config.\n"
     ]
    },
    {
     "ename": "MaxRetryError",
     "evalue": "HTTPConnectionPool(host='localhost', port=80): Max retries exceeded with url: /apis/v1beta1/healthz (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001CC1017FF88>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it'))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\envs\\kubeflow\\lib\\site-packages\\urllib3\\connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    174\u001b[0m             conn = connection.create_connection(\n\u001b[1;32m--> 175\u001b[1;33m                 \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dns_host\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mport\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mextra_kw\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    176\u001b[0m             )\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\kubeflow\\lib\\site-packages\\urllib3\\util\\connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[0;32m     94\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0merr\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 95\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     96\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\kubeflow\\lib\\site-packages\\urllib3\\util\\connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[0;32m     84\u001b[0m                 \u001b[0msock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource_address\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 85\u001b[1;33m             \u001b[0msock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msa\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msock\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mConnectionRefusedError\u001b[0m: [WinError 10061] No connection could be made because the target machine actively refused it",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\envs\\kubeflow\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    709\u001b[0m                 \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 710\u001b[1;33m                 \u001b[0mchunked\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mchunked\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    711\u001b[0m             )\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\kubeflow\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    397\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 398\u001b[1;33m                 \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mhttplib_request_kw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    399\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\kubeflow\\lib\\site-packages\\urllib3\\connection.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, body, headers)\u001b[0m\n\u001b[0;32m    238\u001b[0m             \u001b[0mheaders\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"User-Agent\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_default_user_agent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 239\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mHTTPConnection\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\kubeflow\\lib\\http\\client.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1280\u001b[0m         \u001b[1;34m\"\"\"Send a complete request to the server.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1281\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_send_request\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1282\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\kubeflow\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_send_request\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1326\u001b[0m             \u001b[0mbody\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'body'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1327\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mendheaders\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1328\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\kubeflow\\lib\\http\\client.py\u001b[0m in \u001b[0;36mendheaders\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1275\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mCannotSendHeader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1276\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_send_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage_body\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1277\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\kubeflow\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_send_output\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1035\u001b[0m         \u001b[1;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1036\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1037\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\kubeflow\\lib\\http\\client.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    975\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_open\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 976\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    977\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\kubeflow\\lib\\site-packages\\urllib3\\connection.py\u001b[0m in \u001b[0;36mconnect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 205\u001b[1;33m         \u001b[0mconn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_new_conn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    206\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_prepare_conn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\kubeflow\\lib\\site-packages\\urllib3\\connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    186\u001b[0m             raise NewConnectionError(\n\u001b[1;32m--> 187\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Failed to establish a new connection: %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    188\u001b[0m             )\n",
      "\u001b[1;31mNewConnectionError\u001b[0m: <urllib3.connection.HTTPConnection object at 0x000001CC1017FF88>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-8ddd39b3b983>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mclient\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mClient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m   \u001b[1;34m'''Calculates sum of two arguments'''\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0ma\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\kubeflow\\lib\\site-packages\\kfp\\_client.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, host, client_id, namespace, other_client_id, other_client_secret, existing_token, cookies, proxy, ssl_ca_cert, kube_context, credentials, ui_host)\u001b[0m\n\u001b[0;32m    195\u001b[0m         self._healthz_api = kfp_server_api.api.healthz_service_api.HealthzServiceApi(\n\u001b[0;32m    196\u001b[0m             api_client)\n\u001b[1;32m--> 197\u001b[1;33m         if not self._context_setting['namespace'] and self.get_kfp_healthz(\n\u001b[0m\u001b[0;32m    198\u001b[0m         ).multi_user is True:\n\u001b[0;32m    199\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\kubeflow\\lib\\site-packages\\kfp\\_client.py\u001b[0m in \u001b[0;36mget_kfp_healthz\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    409\u001b[0m                         max_attempts))\n\u001b[0;32m    410\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 411\u001b[1;33m                 \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_healthz_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_healthz\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    412\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    413\u001b[0m             \u001b[1;31m# ApiException, including network errors, is the only type that may\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\kubeflow\\lib\\site-packages\\kfp_server_api\\api\\healthz_service_api.py\u001b[0m in \u001b[0;36mget_healthz\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m         \"\"\"\n\u001b[0;32m     62\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'_return_http_data_only'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_healthz_with_http_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# noqa: E501\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_healthz_with_http_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# noqa: E501\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\kubeflow\\lib\\site-packages\\kfp_server_api\\api\\healthz_service_api.py\u001b[0m in \u001b[0;36mget_healthz_with_http_info\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    146\u001b[0m             \u001b[0m_preload_content\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlocal_var_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'_preload_content'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m             \u001b[0m_request_timeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlocal_var_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'_request_timeout'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 148\u001b[1;33m             collection_formats=collection_formats)\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\kubeflow\\lib\\site-packages\\kfp_server_api\\api_client.py\u001b[0m in \u001b[0;36mcall_api\u001b[1;34m(self, resource_path, method, path_params, query_params, header_params, body, post_params, files, response_type, auth_settings, async_req, _return_http_data_only, collection_formats, _preload_content, _request_timeout, _host)\u001b[0m\n\u001b[0;32m    367\u001b[0m                                    \u001b[0mresponse_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mauth_settings\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    368\u001b[0m                                    \u001b[0m_return_http_data_only\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcollection_formats\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 369\u001b[1;33m                                    _preload_content, _request_timeout, _host)\n\u001b[0m\u001b[0;32m    370\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    371\u001b[0m         return self.pool.apply_async(self.__call_api, (resource_path,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\kubeflow\\lib\\site-packages\\kfp_server_api\\api_client.py\u001b[0m in \u001b[0;36m__call_api\u001b[1;34m(self, resource_path, method, path_params, query_params, header_params, body, post_params, files, response_type, auth_settings, _return_http_data_only, collection_formats, _preload_content, _request_timeout, _host)\u001b[0m\n\u001b[0;32m    183\u001b[0m                 \u001b[0mpost_params\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpost_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m                 \u001b[0m_preload_content\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_preload_content\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 185\u001b[1;33m                 _request_timeout=_request_timeout)\n\u001b[0m\u001b[0;32m    186\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mApiException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m             \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbody\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPY3\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\kubeflow\\lib\\site-packages\\kfp_server_api\\api_client.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, query_params, headers, post_params, body, _preload_content, _request_timeout)\u001b[0m\n\u001b[0;32m    391\u001b[0m                                         \u001b[0m_preload_content\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_preload_content\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    392\u001b[0m                                         \u001b[0m_request_timeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_request_timeout\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 393\u001b[1;33m                                         headers=headers)\n\u001b[0m\u001b[0;32m    394\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"HEAD\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    395\u001b[0m             return self.rest_client.HEAD(url,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\kubeflow\\lib\\site-packages\\kfp_server_api\\rest.py\u001b[0m in \u001b[0;36mGET\u001b[1;34m(self, url, headers, query_params, _preload_content, _request_timeout)\u001b[0m\n\u001b[0;32m    232\u001b[0m                             \u001b[0m_preload_content\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_preload_content\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m                             \u001b[0m_request_timeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_request_timeout\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 234\u001b[1;33m                             query_params=query_params)\n\u001b[0m\u001b[0;32m    235\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    236\u001b[0m     def HEAD(self, url, headers=None, query_params=None, _preload_content=True,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\kubeflow\\lib\\site-packages\\kfp_server_api\\rest.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, query_params, headers, body, post_params, _preload_content, _request_timeout)\u001b[0m\n\u001b[0;32m    210\u001b[0m                                               \u001b[0mpreload_content\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_preload_content\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m                                               \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 212\u001b[1;33m                                               headers=headers)\n\u001b[0m\u001b[0;32m    213\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0murllib3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSSLError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"{0}\\n{1}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\kubeflow\\lib\\site-packages\\urllib3\\request.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, fields, headers, **urlopen_kw)\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_encode_url_methods\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m             return self.request_encode_url(\n\u001b[1;32m---> 75\u001b[1;33m                 \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfields\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfields\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0murlopen_kw\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m             )\n\u001b[0;32m     77\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\kubeflow\\lib\\site-packages\\urllib3\\request.py\u001b[0m in \u001b[0;36mrequest_encode_url\u001b[1;34m(self, method, url, fields, headers, **urlopen_kw)\u001b[0m\n\u001b[0;32m     94\u001b[0m             \u001b[0murl\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;34m\"?\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0murlencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfields\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mextra_kw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m     def request_encode_body(\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\kubeflow\\lib\\site-packages\\urllib3\\poolmanager.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, redirect, **kw)\u001b[0m\n\u001b[0;32m    373\u001b[0m             \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    374\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 375\u001b[1;33m             \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mu\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest_uri\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    376\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    377\u001b[0m         \u001b[0mredirect_location\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mredirect\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_redirect_location\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\kubeflow\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    824\u001b[0m                 \u001b[0mchunked\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mchunked\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    825\u001b[0m                 \u001b[0mbody_pos\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbody_pos\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 826\u001b[1;33m                 \u001b[1;33m**\u001b[0m\u001b[0mresponse_kw\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    827\u001b[0m             )\n\u001b[0;32m    828\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\kubeflow\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    824\u001b[0m                 \u001b[0mchunked\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mchunked\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    825\u001b[0m                 \u001b[0mbody_pos\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbody_pos\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 826\u001b[1;33m                 \u001b[1;33m**\u001b[0m\u001b[0mresponse_kw\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    827\u001b[0m             )\n\u001b[0;32m    828\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\kubeflow\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    824\u001b[0m                 \u001b[0mchunked\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mchunked\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    825\u001b[0m                 \u001b[0mbody_pos\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbody_pos\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 826\u001b[1;33m                 \u001b[1;33m**\u001b[0m\u001b[0mresponse_kw\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    827\u001b[0m             )\n\u001b[0;32m    828\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\kubeflow\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    784\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    785\u001b[0m             retries = retries.increment(\n\u001b[1;32m--> 786\u001b[1;33m                 \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_pool\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_stacktrace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    787\u001b[0m             )\n\u001b[0;32m    788\u001b[0m             \u001b[0mretries\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\kubeflow\\lib\\site-packages\\urllib3\\util\\retry.py\u001b[0m in \u001b[0;36mincrement\u001b[1;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[0;32m    590\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    591\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnew_retry\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_exhausted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 592\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mMaxRetryError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_pool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merror\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mResponseError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcause\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    593\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    594\u001b[0m         \u001b[0mlog\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Incremented Retry for (url='%s'): %r\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_retry\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMaxRetryError\u001b[0m: HTTPConnectionPool(host='localhost', port=80): Max retries exceeded with url: /apis/v1beta1/healthz (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001CC1017FF88>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it'))"
     ]
    }
   ],
   "source": [
    "def add(a: float, b: float) -> float:\n",
    "  '''Calculates sum of two arguments'''\n",
    "  return a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_op = create_component_from_func(\n",
    "    add, output_component_file='add_component.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'client' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-6ee3f6d9b903>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;31m# Create a pipeline run, using the client you initialized in a prior step.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m \u001b[0mclient\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_run_from_pipeline_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0madd_pipeline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marguments\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marguments\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'client' is not defined"
     ]
    }
   ],
   "source": [
    "import kfp.dsl as dsl\n",
    "@dsl.pipeline(\n",
    "  name='Addition pipeline',\n",
    "  description='An example pipeline that performs addition calculations.'\n",
    ")\n",
    "def add_pipeline(\n",
    "  a='1',\n",
    "  b='7',\n",
    "):\n",
    "  # Passes a pipeline parameter and a constant value to the `add_op` factory\n",
    "  # function.\n",
    "  first_add_task = add_op(a, 4)\n",
    "  # Passes an output reference from `first_add_task` and a pipeline parameter\n",
    "  # to the `add_op` factory function. For operations with a single return\n",
    "  # value, the output reference can be accessed as `task.output` or\n",
    "  # `task.outputs['output_name']`.\n",
    "  second_add_task = add_op(first_add_task.output, b)\n",
    "\n",
    "# Specify argument values for your pipeline run.\n",
    "arguments = {'a': '7', 'b': '8'}\n",
    "\n",
    "# Create a pipeline run, using the client you initialized in a prior step.\n",
    "client.create_run_from_pipeline_func(add_pipeline, arguments=arguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'TaskSpec' object has no attribute 'output'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-281b1fcd3e39>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mcomponent_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_component_from_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mload_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbase_image\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBASE_IMG\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mhh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcomponent_1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mhh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'TaskSpec' object has no attribute 'output'"
     ]
    }
   ],
   "source": [
    "component_1 = create_component_from_func(load_data, base_image=BASE_IMG)\n",
    "hh = component_1()\n",
    "hh.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Test(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "    def __getitem__(self, item):\n",
    "        return {\n",
    "            \"text\": self.df.loc[item, \"text\"],\n",
    "            \"marker\": self.df.loc[item, \"marker\"]\n",
    "        }\n",
    "    def __len__(self):\n",
    "        return len(self.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"marker.csv\")\n",
    "obj = Test(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = DataLoader(obj, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': ['Yeah so this particular login screen code you have already shared it with me right?', \"Yeah I have shared with you and divesh both of you. Ok ok got it. Yes. And uh this field I don't know the exact fields so I just mention as a engineering meeting in the dropdown, so whatever fields anyway it will be coming dynamic right there is an\", 'Yeah divesh please go ahead. This piece of code is not working right?', 'Hello yes divesh your voice is not audible. Hello yeah yes divesh'], 'marker': ['Others', 'Others', 'Others', 'Others']}\n",
      "{'text': ['I think. Still some noise is happening. This piece of code is not working. Okay', \"So what's happening? So can you show your screen? So what is happening\", \"Okay one second, I need to open all the files. Yes. Yes right. Yes so like in this case, suppose if you choose any mp4 file so it is not saving in that actual folder because the HTML file doesn't have some like some packages to top with the flask API. So himanshu said we can try with react js.So that js you can write it no problem\", \"Js you can write it no problem, see If you write in react also you need to write this all the types of input types rest of the you need to write an HTML attribute. So without HTML attributes you can't create as a fields.\"], 'marker': ['Others', 'Others', 'Action Plan Tracking', 'Proactiveness']}\n",
      "{'text': [\"As I said yeah the back end of this code was not working. So what we'll do is we'll see this UI part, which he has made we will just keep this UI part while the back end part, we will connect it with react. Yeah.\", 'Yeah that is what correct yeah. Ok himanshu. Even I have shared with you and divesh right? ', \"Oh okay then it's fine. So I have used previously so this code. Actually I was, it was running, I have used somewhere but not this project so when I have previous company I have used same code, might be the code was changed I guess I don't know so you can try with the react only, no problem in that yeah. \", \"So uh suresh for this screen I guess uh as of now it looks video screen I mean upload screen, maybe later we will have to change it with to the Anthem standards so I will share with you. Yeah yeah yeah. Yes exaxtly. I'll share you few files which I have with me, so i'll share you, you can take intuition from that and you can change it but coming to the dashboard part if you can share it, the dashboard. Sure. Yes yeah so this particular part i guess we need to make i mean uh as of now it is i mean the buttons colour and everything has been changed but it is still, it is looking like uh what Kajari gave us. So I feel that, did you, did you get a chance to go through the fireflies and otter, uh websites? yeah\"], 'marker': ['Proactiveness', 'Others', 'Others', 'Proactiveness']}\n",
      "{'text': [\"Yeah I have go through that fireflies so they have used the thing is no himanshu I don't have any color code options, so our logo both logo's are in blue colour so we have to retain the both colour so that is why I have throughout website I have used in a blue colour only so if you have any suggestion we can change it accordingly. Okay\", 'So did you go through that slide I mean in the slide of Kajari where in the last few slides she attached a few screenshots from uh fireflies. Did you have a look at that?', \"Yeah I'll share I'll share wait. Sure just share. So if you look at this okay this is the otter but obviously otter is the mobile one, but yeah, this one, if you'll see, just a moment, it's still loading, okay so this one the fireflies okay. So you can see here there are i mean theme is same, but the way they have presented it is different right? yeah\", \"so here, you can see the theme is same but the way the things have been mentioned, it's different right? Yeah. So you can see, I mean, if you compare this with the UI that, uh, has been generated, it's totally different. Here you can see You can see it's minimalistic, but yet it, it is looking beautiful. So yeah we were expecting something with, uh, on this theme And even if I come here, even though it's a mobile view, but okay uh, if you look at, um, um, maybe the, uh, the buttons format or the theme's format, or maybe even though it is looking like a white background but it is not actually white. It has a slight tinge of grey here  yes. right?. yes same was here. same way it's a theme where it starts with white and ends with grey. yes. so it's in grey colour they have given okay. and if you look at the buttons as well. this button is having like uh slight tinge of blue blue but not exactly. And, uh they are transparent, so uh uh\"], 'marker': ['Others', 'Mentoring&Engagement', 'Others', 'Proactiveness']}\n",
      "{'text': [\"I'm not saying to make the same screen. I'm saying. Okay. Take a hint from this. Okay. Yeah I got it yeah. Okay. Yeah just take a hint from this and try to make it here, it is looking like a website. Okay. Okay but uh there it is looking like normal I mean what we say, the POC that we make or something we just made just for the showcase, not for the production level. Right? So in our case what is the issue? Is that here in our case, whatever, the models that we have built that models are not that much level because here we are trying to get the funding so we can not make the backend beautifiul. As of now, because we have the least time but if the frontend looks beautiful, then whatever is happening in the backend. That is the secondary part, because whatever we want to show, we have a script of that. And we will show that for the three meeting files, but if they are, as the, as the rule goes, right, the first impression is the last impression. So this UI is the first impression. So like the UI you made for the login screen, the home screen, sorry, where we are uploading. It looks like a website, even though maybe we need to change the color later based on the Anthem format, but it's still, it looks like a website, but the second is It looks like a temporary work. I mean, I hope you're understanding. Don't take me\", \"Yeah so keep it only I'm not saying to change the structure. Okay. Keep it this only. Cool. Okay but the themes but the, the way that you look at the button, it is dark blue and dark white. Right? Okay. There okay you can see it. There is a gradient that is a transparency. got it got it.  like all the changes make it beautiful. Right. Similarily it was lines. If you see overview and timeline, there are two lines here.Okay but, It's okay. We don't want these lines. If there is some kind of a transition that we are able to differentiate that. Okay. \", \"the videos of, uh, fireflies and you can get there. That's why, I guess Kajari told you to watch those videos. They know they have clearly shown there\", \"So this, uh, I mean, uh, we can say that for the last sprint UI wireframe has been completed, but for this sprint I have created a new user story only for the beautification part. So what I'm seeing, what I'm trying to say, uh, um, uh Suresh. Okay.  That, uh, one second. Okay. So if I look at your screen, and then if I look at my screen, one second, the screen which i have already made. So i now i am connected to wifi. So now, it will not be an issue. \"], 'marker': ['Proactiveness', 'Proactiveness', 'Action Plan Tracking', 'Proactiveness']}\n",
      "{'text': [\"Okay so now if I open chrome. Yeah so it is almost same. Right? So if you see here, we have this thing also, and this thing also, but my website is also not looking professional and same I can say with yours as well, only for this page only for dashboard correct? So that's what. okay i'm trying to say. That uh the same thing what you have made on the same theme i have made as well. Maybe there are a few extra components here, but neither this is  required nor that is required. We want something on the theme of fireflies and otter. So that's why i have created the story as well. And, uh we can work on that together. So maybe we can connect daily.\", 'the design I mean the components will stay the same okay division remain the same. Everything will remain the same only the structure of button, the transition and uh some other elements they should change', \"Uh but that means the UI is still in-progress, right? It is not ready for the changes. Has to be made and then only it will be ready. Yeah that's correct. Okay fine. So that's why so sravanthi has\", \"this time I have given everyone work. So those who already have the work, they will keep on doing that. And those who don't have the work, they will be helping me out in the react js. Yes so this time no one is getting away with react js \"], 'marker': ['Proactiveness', 'Proactiveness', 'Action Plan Tracking', 'Action Plan Tracking']}\n",
      "{'text': [\"In review? Yes. In progress. Yes. Everything will be done by five, or 5:30 Yes okay cool I'll try to finish it so 4 only but yeah\", \"okay, fine. So team, uh, we would be starting our sprint two from today only. So all the stories would be moved to in-progress.  So please, please, please plan accordingly and let us know the time you need to take. Okay. Now we'll start the sprint planning okay clear okay over to you himanshu\", \"Sure. Yeah. Yeah. Okay. So few more needs to be added and uh, I mean maybe add it. So that's why I have, uh, kept it blank below, but whatever I thought of that I will be going one by one. So first I will be explaining the user story. Then I will be writing the description. Then together, we will come up with the acceptance criteria. And once we finish all of these things, then Sravanthi today only will have this new story point, uh, that only tool that you asked me i showed us the same tool yes using only? yes\", '11. 11 okay fine so um team, you decide shall we do for planet poker last time as we did or is it okay because I think here the most decision should be taken by Suresh even thought the ownership lies across everybody and the team is working on it. And also, uh Himanshu i would suggest you take the acceptance criteria from Suresh.'], 'marker': ['Action Plan Tracking', 'Action Plan Tracking', 'Action Plan Tracking', 'Proactiveness']}\n",
      "{'text': [\"Yeah. Yeah. So this below part. So if suppose a button is selected, suppose this one, then like this, it should get activated. So audio, video and snippets. Sorry. Yeah. Key frames. So if I click on this, then a pop up should come and where your all key frames should be coming. So now, uh, here, summary is there. So, uh, wherever you find that the screen is being shared. Okay. There, uh, in that particular, uh, what do we say? Um, um, if you look at the JSON, uh, we have the transcription JSON for each row. So for the transcription, JSON, for each row, if the screen is shared, there only the integration must be done for that particular row.  So are you getting me Amit? Yes yes yes so do you want me to show open the JSON and show it again? Yes yes definitely Okay um JSON i'll go to desktop.\", 'Oh, okay. So can we have This logic that if this start time and end time lies between your folder list then we can have a status as yes. And label as something whatever is the label', \"Different labels if that time interval has 2 different labels then we will have 2 uh this label will have a list. Maybe let's call it as list \", 'Then we can go, uh with the  folder only, right then it will be only one label Extracted. So if, if this start time, end time, uh, comes under one folder, that means folder label will come here. Will come here okay. Okay and then we have path so we will have keyframe path coming here full folder path complete folder path folder path will be coming here yeah. So this is possible right?'], 'marker': ['Proactiveness', 'Proactiveness', 'Proactiveness', 'Proactiveness']}\n",
      "{'text': [\"two folders or three folders are coming okay. Then let's keep it as a list only. So generally in this list, we will be having only one label, but if possible, if there are more labels, then we will have 2 or 3 labels present inside \", \"Okay okay so um so once the status is yes. This will change from grey to maroon so what I thought is that if I click on this maybe a popup or something will come where the thumbnails will get shown. So maybe if I click on this one, small pop-up will come. And uh that will show.  So nothing will be required from your side, there it will be uh work. Yeah um, so what do we say so so we'll go to this path and that will make us inside the folder. We will choose randomly 2 or randomly 3 images. if there are 3 folders, then we will choose randomly 2,2,24, all the 3 folders.\", '2,3 things. So you will have suppose, uh we will make 5 keyframes, UI and there we will have if there are 3 folders and maybe 2,2,1. if there are 4 folders then 1,1,1, and 2 something like what we will do. And then we will also also have an option to have a detailed view, as well later', \"Yes. So you have to write this logic and then you will have to put it in the Avinash code hmm okay so this transcription I'll send you\"], 'marker': ['Proactiveness', 'Proactiveness', 'Proactiveness', 'Proactiveness']}\n",
      "{'text': ['So for all the rows where there are no keyframes it will be N and label and path will be empty', 'If keyframes are present then it will be yes and label and path will be having contents strings yeah', 'you will have to tell us. So the first description, I mean, the description is that, uh, key frames detection and extraction should be integrated with original JSON. If keyframes are not present, then status should be true or false or yeah, false represented by N if present, then true if represented by Y and respective labels folder paths should be saved in a list.', 'Is this?I mean you, if you want Avinash to access this through an API which means he sends I guess that would be the best wat. So he sends uh JSON to your API and your API populates yeah like that transfers it to'], 'marker': ['Proactiveness', 'Proactiveness', 'Proactiveness', 'Proactiveness']}\n",
      "{'text': ['Sounds good to Amit anything else to add? I guess it sounds good. Okay perfect so 3 story point game we will play at the end. So okay so now suresh this is yours only. So here you will have to, so this one I have created based on the revised wireframes that should come uh after you analyze yes otter and uh fireflies and you will make the changes so yeah', 'So I will send you the Anthem standard page and based on that you have to make the changes sure um himanshu', 'okay. So now comes the, okay. First I will move on to this last one where, so, avinash you will  have to, uh, talk with all the team members, whoever are the owners of, uh, their respective APIs and, uh, we have to stitch it now that routes that you were talking about that routes you will have to finish it', 'I need to call all the routes correct'], 'marker': ['Action Plan Tracking', 'Proactiveness', 'Proactiveness', 'Action Plan Tracking']}\n",
      "{'text': [' okay. So ideally I need to create one more API which will call us the route or something like that or function uh ', \"So all of I mean what you have to do is everyone has an API right? hmm yes yes so once you have generated the JSON you create one more JSON okay you save it in mongo DB it's okay and you pass that JSON as in\", \"JSON okay  you save it in Mongo DB it's okay and you pass that JSON as in as a post request to suppose uh divesh\", 'I mean divesh team saves it and in mongoDB and they forward it to suppose uh Amit Anuj '], 'marker': ['Proactiveness', 'Proactiveness', 'Proactiveness', 'Proactiveness']}\n",
      "{'text': ['When anuj takes it and then gives another JSON and that passes to amit JSON okay okay and that JSON which is the final JSON', \"Okay that will be used to populate the UI I'm okay understood yes sir himanshu actually we have 2 options we can also pull it from Mongo DB like if you're passing as post or we can also pull it from mongo DB it can be from our escalation yes\", 'So that means avinash saved it in mongo DB and then uh divesh will take it from mongo DB yeah divesh will save it in his collection', \"Hmm yeah divesh will take it in his collection and then Anuj will take it from divesh's collection and then I will take from collection\"], 'marker': ['Proactiveness', 'Action Plan Tracking', 'Proactiveness', 'Proactiveness']}\n",
      "{'text': ['Avinash will run that code. So first divesh uh in the first Avinash API will run. If that completes then only uh divesh API will run okay', 'Divesh route will not be called until and unless the JSON is saved in mongo DB yeah', 'Please go ahead was like request will be saved in the collection of Avinash and then it will get to divesh we and divesh API will collect the uh JSON from avinash collection', 'Avinas can show you the process the code the request to get 1 he will maybe show you after this'], 'marker': ['Proactiveness', 'Action Plan Tracking', 'Proactiveness', 'Action Plan Tracking']}\n",
      "{'text': [\"So stitching of all the API's and generating the final JSON that will be feeded by UI oh sorry english okay okay\", \"Of routes that will tell that will ask the next API to start a second API's output JSON to we save in 1 mongo okay 3rd each API.\", \"we'll call 1 API and internally we'll call 1 API and inside your API I will call anuk's API like that. So all the API's will be talking internally but publicly exposed API will be only 1 API yes okay\", 'So this acceptance criteria is perfect yeah yeah perfect okay so based on this acceptance criteria only you guys create your sub tasks. Okay create 4 sub-tasks and.'], 'marker': ['Action Plan Tracking', 'Action Plan Tracking', 'Proactiveness', 'Action Plan Tracking']}\n",
      "{'text': ['uh I have asked for few softwares so that uh Ankur has to update ', 'So we can start tomorrow or day after tomorrow. So can you parallely ping Ankur as well that uh if he can', \"Okay? Will be fine. I'll just push it to backlog and then accordingly when the sprint 1 starts I'll uh we can uh move it to sprint 1.  correct yeah. Okay fine so this one is on me, fine I'll do that. So any other uh impediments or the team is waiting for any other stuff here? Uh, himanshu two things on me. One is uh to fix this. yes. so that you can move it to done. The workflow needs to be fixed and this this has to be moved to backlog Yeah okay so any other stuff team would like to come up here or ask ?\", \"uh yeah my side is clear so, so you don't have any, rest of the team? No I have I have 6 oh clock meeting with Himanshu and Kajari. So I'll if I have anything I'll talk to them\"], 'marker': ['Proactiveness', 'Collaboration', 'Action Plan Tracking', 'Proactiveness']}\n",
      "{'text': [\"And uh today. Sir It's actually Anuj, after you it is on Anuj yeah. Anuj you can start on the uh Wednesday meeting\", \"Today? Anuj. Oh it's it's mine? Yesterday was yours. Today? Mine. Mine. Mine bhanu or avinash? Bhanu bhanu. Bhanu bhanu okay. So you guys can start today and uh I have also started not getting time to finish it, it's still going slow I'll also finish it. Parallely you guys also start. Okay okay. I'll share my screen let's start with the stand up  and then we'll move on to questions, which means technical questions. Okay. So let's just start with the testing. \", \"Them that how you tested it and how you feel that it's working fine. Okay.? Just a comment yes. Is there any supporting document? Any accurate excel sheet or anything you want to attach, you can attach that as well. Yes I'll do. Perfect. So next is, uh, extraction of technologies being discussed. So\", 'Yeah, uh, mine, uh Divesh and, uh, dhanuj all three of us have tested it uh in for an excel sheet of transcript.'], 'marker': ['Action Plan Tracking', 'Collaboration', 'Action Plan Tracking', 'Collaboration']}\n",
      "{'text': ['Okay so that means yours and hive 3 and hive 5 all are completed right?', 'Yes himanshu. Actually I have created the code in bitbucket and I put some cse file sheet cse file going to check', 'today I add some code in that main function to convert the output to JSON so after the stand up I will update on that so I will again push ', 'Sure himanshu. Even though the function is almost same, but you guys are able to extract tools and whatever is your individual user story using that function right? Yes . Because why I am asking this is because when the sprint review call will take place even though you have written this common function, but suppose divesh, you will have to pass the '], 'marker': ['Action Plan Tracking', 'Action plan Tracking', 'Action plan Tracking', 'Action plan Tracking']}\n",
      "{'text': ['Uh yes sir so, actually there are I have added the comments and attached the code so what is now currently I am like in excels I am uh running on the test cases and uh there were some exceptions there. So I am mentioning that in excel and I will attach that document today', 'Uh so you just add those execpetions as a comment here while others other exceptions you put It there uh if it can be done in this sprint or the first 3 sprints, I will put it back to in-progress. Otherwise I will move to in-review. Okay?', 'Uh I am putting it in in-review but. Okay you have to add comments okay? What are the test cases? Which are execptions? Okay sir I will add', \"Yeah next is anuj. Uh yes sir uh I'll I mean I'm done with the code I've tested it I'll be uploading the file's output and then what I have provided the manual input. Okay\"], 'marker': ['Action plan Tracking', 'Proactiveness', 'Action plan Tracking', 'Action Plan Tracking']}\n",
      "{'text': [\"So provide your comments, attach the supporting documents and then I will start the review. Okay. I guess this task has also started which is creation of text snippets. So I will be putting it in-progress. So first I will start with hive 20. So already I know dhanuj uh what you are facing so let it let let me keep it in in-progress only. i'll have a discussion with you on this, in sync up after this okay okay sir. let's move on to transcript cleaning. So avinash?\", \"Yes sir, so yesterday I've told you I've tried with a bi-directional LSTM Model, so it's not actually predicting domain specific words, so what I did was I created a script which will extract all the vocabulary for us from the manual transcripts and also working on one more model for spelling correction only RN based. okay\", \"Yes sir, I have tried but uh rev.ai also like not correcting entirely I mean not correctly predicting all the domain specific words, some words it's actually predicting\", 'Yes as Sarika mentioned day before yesterday. All the, all the sentences were repeating actually from previous output and next output like some part of the sentence is repeating in the next diarrization output also. So I have removed that also.'], 'marker': ['Proactiveness', 'Proactiveness', 'Action Plan Tracking', 'Proactiveness']}\n",
      "{'text': ['Those words which are causing you the, just add those words here or add those sentences here so that we can also see that. Okay these are the problems.', \"I guess it entirely depends on the vocabulary but uh current vocabulary list uh regarding that it's better, it's 40% better than the previous output. Approximately 40%, so add, \", 'is 4 one second. Thursday, 4th is Thursday, next right? Yes yes, next Thursday okay then give it a try till tomorrow. Yes ', \"Yeah uh even this is done I'll add comments. There is one rare exception I'll discuss with you later. Uh in the with the earlier code I was able to complete this one as well. Uh I'll move it to, you can move it to review, I'll update the comments.\"], 'marker': ['Action Plan Tracking', 'Action Plan Tracking', 'Action Plan Tracking', 'Action Plan Tracking']}\n",
      "{'text': [\"A manual person can rectify in the UI. Okay. So make it anuj or dhanuj right now and then let me know I will move it to in-review and please add the comments you have not added comments for any of the user stories. Yeah yeah I'll add I'll add Okay so I guess uh for the hive 9 also some updates avijit sent me uh before looking at the code can you explain i mean how how the things are going uh Avijit?\", 'Okay so it was giving you the proper result right? Yeah. Yesterday the JSON format it was giving all . Yeah. The same file? Yeah exactly the same format. Perfect so. You took testing? But ', \"Okay label extraction, yeah it's on anuj's name, so obviously it is dependant on this is done right anuj? And uh this will be done today. So I guess, yeah, then we'll start with this okay?\", '3 minutes of meetings file. One from me, one from anuj and one from Bhanu. So anything else Nikita, Sarika you want to add?'], 'marker': ['Action Plan Tracking', 'Action Plan Tracking', 'Action Plan Tracking', 'Action Plan Tracking']}\n",
      "{'text': [\"That engineering meeting and today also we'll have a sync up call, so that can be engineering because there we are only discussing about engineering.\", 'Yeah that can be a business and you remember, you guys worked on 4 JAM meetings. Yeah.so those can be also business meetings. So we do have the transcript for it we just need to create a manual transcript and then we can give it to you and that will be the business transcript.', 'Definitely so we can start with ADP and later if we need more data we can go with JAM also', \"for the sake of engineering,  for the sake of separate engineering meeting and separate transcript generation let's connect in a sync up call and let's discuss because I guess for the dhanuj uh code we have to discuss few things and avijit wanted to show something, so let's connect on it on the sync up call okay? \"], 'marker': ['Action Plan Tracking', 'Action Plan Tracking', 'Action Plan Tracking', 'Proactiveness']}\n",
      "{'text': ['Cool so at 3:30 I have meeting with Shilpa and sravanthi so at the same time you can also join and yeah you can have', \"so today who's uh MoM writing, date was the 3rd person.\", 'okay so whatever Is the discussion as much detailed as possible and just write down.the points okay? ', 'and pen that will be a little faster because this MoM is not for uh like general MoM so which we upload in confluence this is for the model training so'], 'marker': ['Action Plan Tracking', 'Action Plan Tracking', 'Proactiveness', 'Proactiveness']}\n",
      "{'text': [\"So, okay. So I'll repeat whatever I said before the recording. So avinash you have done for the first video, you have done the classification task as well. So now for the second video, you do the same thing. Uh, tell the classification and both the Excel sheets you can share So that will be the first task done. Then one second  let me share that, uh, um, that Excel sheet where I created the plan. One second.  \", \"Getting assigned with uh, epics and a task is beside them and based on the sprint planning. We will continue. But for this week, uh, till uh, uh, sravanthi's completely onboarded into inside this project, maybe we'll have to continue with this particular table.  Okay so for avinash speaker diarization is done with for first video the second video you guys will generating now the next thing is spell checkers and summary clean up so actually spell checker is part of summary clean up only so avijit and avinash you both will be working on this so avijit\", 'I will be giving you the KT at 3:30 but still. ', \"You can parallely work with avinash yeah sure on the summary it's a normal NLP task. So you can, I mean, uh, for the first video you have the MoM, the manual MoM as well. as The generated transcript. So you will, you both will have to see what kind of error so avinash the same task, the red pointers that you had in the previous Excel sheet, same thing you will have to do. You both have to come up with a strategy, like how this can be automated, whether we have to create a custom dictionary, or uh, anything. So first you will have to compare both the transcripts and then come up with the strategies based on that. So once every. Avinash you also shared, you shared it with the WhatsApp i mean sorry the team's group then i will also have a look at it i will also compare and maybe i'll also. \"], 'marker': ['Proactiveness', 'Collaboration', 'Action Plan Tracking', 'Action Plan Tracking']}\n",
      "{'text': ['thing is amit and dhanuj. So text summarization, so you will be finding the actual transcript and you will be having the MoM. So you will have to see what are the exact, uh, sentences in the generated transcript, which matches with the MoM. And then based on that, you will have to summarize. So obviously the summarization will be the normal process which you have been doing using Pegasus or T5 after that you will have to see after the summarization, what are those important things and what are not? So you continue with the text summarization, and then after that you will be, uh, giving this summary to, uh, I guess, uh,hrisheek and divesh', 'You have been doing using Pegasus or T-5 after that, you will have to see after. the summarisation what are important things and what are not?', \"topics extraction and, uh bhanu and, uh, anuj till anuj is in the team bhanu. Once anuj leaves the team and we don't have any replacement. And I guess bhanu will join, hrisheek and divesh and because intent extraction or topics extraction, they are almost same. The only thing is. \", 'We already know that we will be classifying questions, exclamations and, uh, some special tasks like that, while topics extraction, like what is the theme on which we are talking about? So whether we are talking about workOS, we are talking about Docker in that particular sentence. So like that you will have to extract those topics'], 'marker': ['Proactiveness', 'Proactiveness', 'Collaboration', 'Proactiveness']}\n",
      "{'text': ['Once the summary given by amit and dhanuj is received by hrisheek and divesh, You guys look at each sentences and see what kind of topics are present there and based on that, you will have to extract those major topics. So suppose in the first meeting we discussed about, uh, uh, I guess bhanu asked the question that why handwritten MoM is required. So then, uh, kajari explained and the entire thing. So with that, the topic extracted can be importance of MoM, uh, importance of manual MoM. So like that for every sentence or every paragraph that we are summarizing. First, we have to check whether there is an important topic or not. And if there is an important topic, what is the topic presented? And based on that, you will have to train the model. So as of now, obviously there is a lot of manual work as well, but then only we can train the model. So first look at the transcripts and come up with a strategy. So either you can use any NLP algorithm, or if you are feeling that NLP algorithm will not work, then you can create a rule based algorithm', 'So if this term is present, then it is definitely talking about this particular topic. So like that you guys have to start then coming to Bhanu and anuj you guys have to extract those themes. So questions. So I guess I have added in my manual thing, I have added. ', \"In the actual transcripts, there can be more questions. So don't only depend on what my, uh, manual transcript is saying. You also look at the actual transcript and see questions. Are there or not actions, discussions, obviously that is there. What is, what are the action items? What are the discussion item, questions, dates. So if there is a deadline something has to be done before a deadline. So that can be one intent with the name deadline. So if there is an intent with the name deadline, then the deadline, which is the actual date that needs to be extracted as well, because later once you will click on the intent of deadline, then that sentence will come in the right-hand side. And then it will tell us  What is the actual date that will be extracted so like that if you look at the presentation which kajari has created on the left-hand side we have all the intents that is the task of bhanu and anuj while on the middle side there are all the what do we say let me share that particular thing as well so that it will become more clear so if you see here\", \"here you can see at minute forty 44 second open-ended questions. One minute, 10 seconds. it is talking about funnel six minutes of it is talking about building a growth team. So this is the topics that we are extracting. So that's the task of divesh and hrisheek, and this is the task  of bhanu and uh anuj \"], 'marker': ['Action Plan Tracking', 'Collaboration', 'Proactiveness', 'Collaboration']}\n",
      "{'text': ['which is you can see tasks, pricing, metrics so obviously we dont have pricing metrics but we do have tasks so in tasks we can have discussion and actions, we have questions we have dates and times that are extracted then there are negative and positive sentiments so if you click on this it will be telling move in on which paragraph we have negative talks on which paragraphs we have positive talks and like that so whatever is feasble based on the two transcripts you guys have to uh start doing that and make a model out of that so that will finish or that will be', \"And then it comes to otter.ai fireflies already the platform architechture I have shared it with kajari uh there are few things that I need to add especially this feedback loop which i will add again and send it again while otter.ai and firefiles today i will be finishing the evaluation cool so any questions? so i guess major questions will start coming once you actually go throught the transcripts so i guess atleast by today i would require that you guys come up with a strategy of what exactly you're extracting what intents you're extracting what topics you're extracting, matching of current MoM with the generated MoM and like that whatever is the analysis you guys come up with that by tomorrow in the next meeting we will be discussing with each team. What is your plan? How you are going to proceed.further\", \"so at 3:30 we all three of us will be meeting I mean four of us avijit yeah shilpa and sravanthi right and I guess bhanu if you want to if you're okay with the project if you've understood then its okay otherwise if you also want to join it to understand then you can also join it It's optional for you. I will just extend it to bhanu. \", \"let me know bhanu If you need, I'll just forward that invite,yeah I have already got a invite But I think it's. no issues  \"], 'marker': ['Proactiveness', 'Action Plan Tracking', 'Proactiveness', 'Proactiveness']}\n",
      "{'text': [\"guys Thank you. Thank you so much for joining the call and, uh, with the other team members let's meet tomorrow and get the solid updates and let's meet. at 3:30\", \"If you don't provide any artifacts again himanshu will come back so that's nothing but you have to both your time will be you know extended, why do you want to do that? Right. So make sure. Ok I'll I'll. Since you have done update them here, attach the related story doc. Okay i'll attach it today. Okay fine. Yeah. What went wrong here. Okay let's move on to your in-progress story first.\", \"Same thing right? Yeah yeah I'm working on the algorithm I should use on this because I have created a dummy data set for this escalation part. Deadline part is almost done. Deadline part is done for so for the escalation part, I'm still figuring out what algorithm to use in that.\", \"Are you waiting for somebody to pitch in and you know you can take help from himanshu if you're not figuring able to figure out what  kind of an algorithm you can use here. Yeah.\"], 'marker': ['Action Plan Tracking', 'Action Plan Tracking', 'Action Plan Tracking', 'Proactiveness']}\n",
      "{'text': [\"So uh I can see depending on your other project's work, I don't want to push it on you. But if you can pull some of the other stories which are on your name which are uh which doesn't have any dependency on the some tasks. Can you please name them so that we can move it to in progress? I guess this has some uh\", \"Okay by when uh by today you'd been owing an information on this? I have to speak with himanshu regarding that after that I'll confirm with you. \", \"Okay thank you and we have and we have the other story which is on bhanu's name extraction of names. Uh yeah uh it's almost same as the other three extractions. I'll have a small discussion with himanshu and I'll update you by evening. Okay. Most probably uh we can move it anyways i will once talk to him and i'll update you.\", \"Okay cool thank you bhanu. And then we have this on uh himanshu's name I believe he has to uh move it to one of the assignee's conversion of code into functions, modules and classes. And, um dhanuj's name we have classification of type of meetings. Dhanuj you have any input on this?\"], 'marker': ['Proactiveness', 'Action Plan Tracking', 'Action Plan Tracking', 'Action Plan Tracking']}\n",
      "{'text': [\"Yeah himanshu suggested some few algorithms like uh but we are lack of training data. It's uh, Kajari said like uh the user will be inputting the uh meeitng type, so uh I just want to get some clarification regarding the data.\", 'Do you want me to talk about it now? Or Sravanthi is it after the meeting?', \"Yeah so we'll keep it in a parking lot and then uh move ahead with\", \"And once it is done we'll still have some time. If we have time we can continue, if not we can talk about it in our sync-up call. Okay alright then ping me I'll tell you\"], 'marker': ['Action Plan Tracking', 'Others', 'Others', 'Others']}\n",
      "{'text': [\"I believe this would be waiting for the rest of the stories to complete, again this would be uh going over or now? No no you don't need other stories to complete. \", \"UI framework design, which should , which should be on suresh's name I believe right? Yeah uh Sravanthi.\", \"Uh Sravanthi, so that I have requested few software so Kajari is evealuating so once it's done\", \"Once it's done, then I have meeting set up with himanshu, then I can work on this. So. Okay. \"], 'marker': ['Others', 'Others', 'Others', 'Action Plan Tracking']}\n",
      "{'text': ['I would suggest, also set up a meeting with me on Wednesday okay. Sure uh will do it.', 'Will do it yeah because of I need the inputs from you and uh himanshu so then I can take it forward.', 'Because of, your wireframe, your UI design should not be dependant on what the team is doing. Yeah that is correct. Yeah. Okay. Because ', \"Because remember the discussions we had that, Nikita and Sarika, they are creating a cleaned up uh scripts. Those will be the hardcoded uh JSON for you and that is the JSON that you that you must finally uh creating. So for you having couple of those JSON's which is filled with already good results is should be enough to do the UI work. This way we can have two parallel transcripts.\"], 'marker': ['Others', 'Others', 'Others', 'Action Plan Tracking']}\n",
      "{'text': ['then we can take forward. Sure. Okay great so we have uh Sarika', 'Sarika and Nikita also, can you please provide your updates as uh what what is been doing? From your, what have you done?', \"Yeah, hi Sravanthi. Hey. So uh, we were working on the audio files of 18th and 21st and 18th was taken care by Nikita and 21st I was uh doing and I finished and submitted to himanshu. So we found some uh observations which I recorded them in the word document and submitted to himanshu which will help uh the team or or uh just want to uh know like if i am reaching their expectations or if anything else i have to do from my end so i tried analyzing the audio files where the machine is missing and uh what all uh to be added hmm uh and uh NER and Label, such kind of stuff i have uh worked on it, so uh i have submitted the excel the final output and the observation along with it. So i'm just looking forward for himanshu to get back to me hmm so that i will know\", \"if i reached the team expectations or not. And then, Okay, yeah, it's really good Sarika.\"], 'marker': ['Others', 'Others', 'Proactiveness', 'Others']}\n",
      "{'text': ['And uh Nikita you have any updates from your end? Yes Hi Sravanthi, hey, can you hear me? Yeah yeah nikita please go ahead. ', \"you don't have to wait for an update. Okay and in the daily sync-up atleast if you can join uh it would be great uh for today. Yeah that's one thing any other uh thing the team would like to discuss here?\", \"so yeah uh daily one person needs to create the manual transcript of that entire meeting. So on Friday, it was on me, so I spent lot of time in creating that so I didn't get time to work on the user story of mine \", 'So whenever you are, it is taking long time for you to uh do it manually right? '], 'marker': ['Others', 'Action Plan tracking', 'Action Plan tracking', 'Others']}\n",
      "{'text': ['Yes uh for entire meeting we need to create that uh transcript. So uh. I mean lot of changes.', 'Okay so how many hours are you spending on that particular task?', '3 and a half hours. But still only half is completed.', 'Let me talk to himanshu uh that. Yes. If it is 3 and a half hours for 1 person '], 'marker': ['Action Plan tracking', 'Others', 'Action Plan tracking', 'Others']}\n",
      "{'text': [\"It will be it will be uh big task right? So let me talk with himanshu and also Kajari. So let's come up with something and uh we'll get back to you on this.okay yeah. Thanks Sravanthi. Okay\", \"we'll get back to you on this.okay yeah. Thanks Sravanthi. Okay. Yeah thank you\", 'So any other. Hi Sravanthi. Yeah. Yeah so i. Yeah nikita. I wanted to ask regarding the training. Is there a category? Where we have to go and choose the training or the can we say anything from our side, what we want to build ourselves into?', 'not at the Legato perspective right so it is for our team, not only for our team for the digital tower if you have to be very specific. So you can just come up with this suggestions which would be helpful for you uh it is it should not be'], 'marker': ['Action Plan tracking', 'Others', 'Others', 'Others']}\n",
      "{'text': [\"So uh make sure that whatever training you are you are taking it or you're suggesting or you want it that should be relevant to your uh work which you are doing\", \"Yeah so this one uh the first one hive 22 so I guess the team needs to uh start committing their code in the branches and uh if they are successfully able to commit it, then this can be done. This can be moved into done. If they are facing any issues then we'll see how what can be solved and so this in-review is pending from the team's side. Well this rev.ai vocabulary, so avinash have you added all your scripts and everything as attachments in this user story? \", \"Yeah because unless and until you don't I mean you add then only I can put it to done so. Yeah. Okay I will add yeah\", \"Because uh what I believe is you know there are all some gaps here you don't have to put my name here maybe I will just add himanshu in the shadow himanshu in this. Uh you may not have to make formal. See, in the call also came a very small small understanding gaps here and there. So it may happen individually the modules are working well but together there are some tweaks.\"], 'marker': ['Others', 'Action Plan Tracking', 'Action Plan Tracking', 'Proactiveness']}\n",
      "{'text': [\"meaning to be done uh to to cover for those gaps that's why an end to end demo if we can do before we move to done\", \"Correct so see what I understand is like in my previous company I was a product owner or product. My job is to see on the done. Because the way we were working there was a safe agile that's why I'm just sharing my thought because I don't know here, it will be a conflict. So we used to uh do safe agile epics, which means after sprint is done an end to end demo should work well. Because it's kind of that version, all the epics should be complete, it should not be half done. If that end to end demo is not working \", \"having a sprint review before we close the whole sprint we're not  keeping the sprint 0 we're not completing the sprint here\", \" then we have an end to end review, end to end, sprint review call with I would be suggesting where I mean setting up there uh himanshu as a product manager or a product owner, he would be explaining what what has been done throughout the sprint 0. oh. and then we'll be closing the sprint.\"], 'marker': ['Action Plan Tracking', 'Action Plan Tracking', 'Action Plan Tracking', 'Proactiveness']}\n",
      "{'text': ['Uh fine so we have only 5 minutes left to join the other call team, any other thing?', \"Yes uh himanshu, uh I'm not seeing any branches in the hive project.\", \"the same bitbucket right? Yes yes. Okay so let's discuss that in the sync up call then. Yeah, okay.\", \"Okay fine, ok team then let's meet at next 5, 4 minutes thank you for joining the call. Have a nice day.\"], 'marker': ['Others', 'Others', 'Action Plan Tracking', 'Others']}\n",
      "{'text': [\"I was working on uh hive 81 that I'm working simultaneously on both hive 108 and 109. I guess today it would be moved to testing. I have written the code actually and I am I will move it to testing today. Okay. That's it from my side.\", \"So you'll be closing the related tasks also right?Yes, yes I'll do. Okay and kindly update the uh artifacts as well, the documents. \", 'Hi everyone, this is avinash, uh regarding my user story which is API stitching. I have integrated a sentiment classifier. The only thing remaining is deadline escalation which I will do today so and then after Amit gives me API I will integrate that as well.', 'Yeah yesterday I have submitted a document to Avinash with the scrum link and what all content it has so anything else you are expecting from me?'], 'marker': ['Action Plan Tracking', 'Others', 'Action Plan Tracking', 'Proactiveness']}\n",
      "{'text': [\"Hi everyone, this is Divesh. My user story is hive 92, I just completed the user story I mentioned in comments as well and the remaining part is I need to combine my code with hrisheek code as well , for message file is correctly successful or not, that we'll do by end of the dsy today.\", 'One second yeah divesh. So it is not a story uh Sravanthi it is just whatever he and hrisheek has done and whatever uh hrisheek has done they just need to make it together. So it is not I mean their task is done. It is just something they need to combine and send it to me. So that later we can have uh routes created', 'Hive 110 and hive 111 are like completed uh and hive 112 is also completed for one colour yesterday I modified the course.', \"Uh yeah Bhanu here uh hive 86 audio snippet logic uh almost development is done, just I moved to testing, just now uh later in this day I'll move to in-review once\"], 'marker': ['Action Plan Tracking', 'collaboration', 'Action Plan Tracking', 'Action Plan Tracking']}\n",
      "{'text': [\"Yeah. Yeah hi this is hrisheek. Yeah yeah so that's file type validation and catching errors so this is done actually you can move it to like in-review because like the code the error message code is uh integrated with divesh only that the success score is it be done. But, as a part of the story only error score is there in this story, so the success measures it's like bit uh like uh addition to that so that is done. so that will be done by today. \", \"So hrisheek if it's going to take uh more time then don't do it, you just finish it and uh you integrate it with divesh code but if you feel that it can be done along with the integration divesh then you can proceed yeah\", 'Yes I mean due date means yeah 3rd 3rd yes. 3rd will be the due date ', 'Hi this is Avijit. Yeah last day dhanuj and bhanu sent their codes, changed my.I have uh Inserted my logic on their code and there was some issue like the orientation of transcript was getting changed so I changed my entire thing and now it is coming fine. I would like to show that in the sync up. Okay so i have attached the screenshots it can be moved to in-review i think. '], 'marker': ['Action Plan Tracking', 'Proactiveness', 'Action Plan Tracking', 'Action Plan Tracking']}\n",
      "{'text': [\"Uh so regarding this I have like uh customise the code with the keys. So, the help with help of avijit yesterday soit's done you can move it to testig or tested I have to attache the documents still. Also sir has to see it's right I mean\", 'so sarika and nikita? Yes hi everyone so I have submitted both the transcripts of the week to sarika meeting 5 and meeting 4. Nikita your voice is very  low. Yeah is it audible now? ', 'First and second and she has to do the latter part and uh the user story nam uh, could we change it?', \"So yeah Nikita you said to change the user story name. we will do that. So there was a lot of background noise. So that's the reason I asked you to go on mute. Okay anythint else from Nikita? I think you can pink Nikita\"], 'marker': ['Collaboration', 'Action Plan Tracking', 'Others', 'Others']}\n",
      "{'text': ['So sarika? Coming to I recevied the two scripts Sravanthi, yesterday and today. So ill be working on labeling the script and uh yeah', 'Okay fine so everything is okay right? Are you people facing any problem in getting the recordings or anything?', \"No uh one question Sravanthi, I just had ato understand is when you click on my uh name and we have a meeting file labeling in to do and meeting 4 labeling in done. When you observe my page, right so my question here is when you click on the Nikita's name there is a meeting 4 labeling and meeting 5 labeling still in meeting 4 transcription and 5 in \", 'Until and unless I received a transcription, I cannot do the labeling right? So I think meeting 4 transcription here in the progress should be like in done I guess we have to move it'], 'marker': ['Action Plan Tracking', 'Others', 'Others', 'Others']}\n",
      "{'text': [\"So that is. No no no I'll tell you what. No no no I'll tell you what. So this meeting transcription 4, this has a complete transcription half of your task and half od nikita's task\", 'So this particular thing I think this should be moved, yeah that is what I am I meant it, one second', \"Oh no no I'll tell. I'm sorry I'm confusing you and I'm getting confused. So each week you are supposed to do 2scripts right? So in the 2 scripts instead of writing 8 I mean 2 each 2 2 that will be that should be coming up to 4 stories right. Instead of making 4 stories we have enhanced the story limit story points. Earlier it was 3, now it is 5. So Nikita can whatever Nikita is doing, the 2nd story, that will be updated here  only and meeting 5 will be having 2 sripts again. So that's the reason if you're completed you're story part here that means this complete labeling is done and okay my question is okay so hmm\", 'discussion I mean just a wordmy doubt is like meeting 4 labeling will have 2 scripts. Meeting 5 labeling. Yes. Will have 2 scripts. Correct. So in that case in meeting 4 labeling. I have uploaded only one script.'], 'marker': ['Others', 'Others', 'Others', 'Others']}\n",
      "{'text': [\"Right. So actually this cannot be moved to done. It should be in in-progress. Hmm yeah. That's the reason just the story points is showing as 5. So the other day we were discussing in the same thing. Instead of having 4 user stories on each of you. Right. we thought 2 stories and we'll increase the story points. Because we have already started the sprint and if we start adding stories more it will be a scope change after the sprint is started, So that's the reason we have changed the story points.  So you are saying whatever a script, you are, the second script, which you are supposed to do, that should be coming into meeting 4 labeling \", 'Okay so where, is there a option to upload another document? ', \"So uh so what we can do is we I'll just check if we can move it back to in-progress hmm I'll just check and let you know\", 'Now that I think Nikita had submitted two scripts right? Right the second'], 'marker': ['Action Plan tracking', 'Others', 'Others', 'Others']}\n",
      "{'text': [\"Yeah, the second one after you do this second one this story will be moving to done. Yeah sure. Only one you have done and it is moved to done no. No it should be having the 2nd script also in this. Yeah true but my, I'll let you know if we can just move it. right back and then you can attach the complete thing here\", 'Can we uh upload the document in the standard option. There there we have a two thing, one is a PHI PHI', 'and the standard so for uploading the document, can I use the same standard option there? For a second script. Yes you can. Okay', \"Yeah no problem, thank you. So anything else, team? Okay I'll take the silence as No ok then let's join at 3:20 call and get your doubts clarifies\"], 'marker': ['Others', 'Others', 'Others', 'Others']}\n",
      "{'text': ['Okay thank you bye bye bye Thank you Sravanthi and team bye bye ', 'So here everything looks good anything is pending? Anyone who has to show I guess bhanu has worked on this part uh audio snippet bhanu can you show that once?', 'And even this is the one on the system uh this is the hmm yes avijit I put the JSON in that UI', 'So this is looking like this okay yeah have put some sample are nice awesome'], 'marker': ['Others', 'Others', 'Others', 'Others']}\n",
      "{'text': [\"even if it, uh, you don't finish it off, you can just show this part, whatever condition is in, you can show it okay because this is our USP. One nice feature that we have added\", 'In future or now? Yeah now future yes now I think can it be downloaded ', 'wow so I guess this functionality is already there so you can in later you can remove this download option directly then yeah can download it from there.', \"I'll just put this uh cross button over here and this snippet and if they want to download they can download from here \"], 'marker': ['Proactiveness', 'Others', 'Proactiveness', 'Others']}\n",
      "{'text': [\"yeah I have 1 more question avijit yeah I'm sharing my screen just yeah so I have put avinash's code here okay so this yeah that where is the keyframes move they moved the data okay I loaded the JSON uh which uh was there which avinash showed so this is this was overview okay okay yeah okay correct wait no overview should which where should it come in the UI? this overview right?\", 'Yeah and here also both times the same thing will come yeah ', 'Later or this left overview we will make it much more smaller right', \"Yes. Yes, it's fine. Can you show go down and, uh, show the summary part? Okay ounds like a plan we can have, so there should be, uh, how to, so how do they make it why it has come in summary. Okay it is showing all the summary in all the transcripts as of now.\"], 'marker': ['Others', 'Others', 'Others', 'Others']}\n",
      "{'text': [\"Nothing will happen. The old things will come no this gets shorter but I don't know these are the\", 'summaries, actions okay so actually summary should be not today but transcript should be everything summary should be only those uh those sentences which are present in that timeline yeah and Anthem tools, tools sentiment, name and deadline yeah hrisheek', \"So I guess today we only have 1 hour of time. So because uh guys Kajari just mentioned that she will leaving at 6:30 so in 1 hour we have to finish everything. Last time a lot of people uh this thing got over I mean they didn't get the chance to attend the demo. yeah yeah so i guess we have to plan it like uh by 6:20 we have to finish it so that after that 10 minutes can be taken by Nikita suresh sarika kajari asks questions then for that as well yeah\", \"Okay so we have similar demo right next week also. Next week, so team don't worry  Um, we have time, so whatever you can show up for this one hour uh stipulated time let's do it and obviously it is really good.\"], 'marker': ['Others', 'Others', 'Action Plan Tracking', 'Others']}\n",
      "{'text': [\"Okay so just a quick note on the today stories. And I don't think we need a sync-u call now, Do we? No no it is a just\", \"then let's quickly touchbase on the sravanthi I have only one doubt with Himanshu so yeah yeah so actually himanshu \", \"I have received that, uh, react app native. So, but I don't have any node in uh my local machine. So I'll do one thing i created this button now so in the Javascript code. And also I'll write it with that old HTML only then you can incorporate with that your code that will be helpful for you \", \"Yeah sure then It's fine yes I will start today. So sravanthi you can make it in-progress that ID is hive 91\"], 'marker': ['Others', 'Others', 'Others', 'Others']}\n",
      "{'text': [\"yeah the changing timelines right? Yes yesh okay and I'll just move it to in-progress\", 'Sarika I have moved the story to in-progress which was closed we were talking about', 'to in-progress so yeah so I believe by next weekend all of the 4 stories should be moved to uh ready for release not weekend at whatever time we have the due date time we thought before the sprint', 'So I have a question here for meeting 4 uh we have a 4 days remaining right? Meeting 4'], 'marker': ['Others', 'Others', 'Others', 'Others']}\n",
      "{'text': ['so hive 95 meeting huh? For this? Yes hive hive I should be moving it to in-progress for now. I think did you get the 3rd uh script? Yeah', \"Fine see I'll tell you what no confusion for per week 2 weeks scripts yeah\", \"scripts each okay hmm okay that makes this stort has 2 scripts this story as 2 scripts this is yeah a week's story\", \"is a week's story done and you, you people should be working on the next the stories already these 2. so it only then you will be able to give me 2 stories per week, which are 4 from your end\"], 'marker': ['Others', 'Others', 'Others', 'Others']}\n",
      "{'text': [\"we can we can touch base offlibe. If you have, if we still get confused or if I'm confusing you.\", \"Yeah okay okay let's move on team let's close it you have so much work to do. Let's give it a quick update on your stories\", \"So I've completed hive 81 and also integrated it I will attach the relevant documents and move it to in-review.\", \"Himanshu it has dependence no it was finished from amit's side yeah \"], 'marker': ['Others', 'Others', 'Others', 'Others']}\n",
      "{'text': [\"Yes yes it it's finished it's done oh okay so himanshu just check the due date for this\", 'Sure uh or bhanu even you can check the due date and let me know because we have just moved it to in-progress I want to check the due date.', 'uh that should be moved on himanshu? So I guess automatically It is taking as 24 I guess I forgot to make the change', 'I will make it as 3rd okay and in one of the user stories you have given you a due date of 2022 February next year due date'], 'marker': ['Others', 'Collaboration', 'Others', 'Others']}\n",
      "{'text': ['you gave 5 days to everyone right? 5 days is over like some people had more than 5 days', \"So I guess what is the task? I will add few user stories I mean another person's tasks complex. We'll break it down into another user story and assign it. Yeah. \", \"Don't add a user story now. Himanshu it will be a scope change. Add a task to him for that user story got it fine okay let's move one dhanuj?\", \"He's also free dhanuj? Yes both worked on the similar kind of tasks and they all they both finished it as well \"], 'marker': ['Others', 'Action Plan Tracking', 'Others', 'Others']}\n",
      "{'text': [\"So bhanu's story has been moved to uh this in-progress today. So bhanu uh do you need any help or can you do it alone? It's a complex one.\", \"What is that story? Adding keyframes logic I guess it will be a complex one. So why don't you? Let's add avijit and bhanu's user story I'll add it add him I'll let create a task I'll add him \", \"Okay so avijit moved avijit this is moved to bhanu okay okay and later you'll see dhanuj\", 'Amit is trying uh optical flow uh once he finishes. I will add the attachment otherwise everything is integrated '], 'marker': ['Action Plan Tracking', 'Collaboration', 'Others', 'Action Plan Tracking']}\n",
      "{'text': ['Divesh yeah I mean why is this story still in yeah I have one progress', 'to do it will be in progress today and I guess dhanuj can be part of uh divesh user story', \"So dhanuj, uh, uh, Divesh, uh, create a task and, uh, assign it to dhanuj. Okay sounds good Sravanthi. Okay anyways you will be breaking those into tasks right? Attach once, uh tasks to dhanuj's name sure \", 'Hrisheek dynamic button logic where the JSON and yeah so I guess he also started'], 'marker': ['Others', 'Collaboration', 'Action Plan Tracking', 'Others']}\n",
      "{'text': [\"hrisheek is facing some power issue. So we don't think he will attend the meeting and he will join okay\", 'demo okay he started the work on the dynamic logic buttons okay ', \"Okay fine so did I anuj. Yeah uh so I'm done with this uh avijit. Send me the updated code have also updated on it sir can today \", \"I'm just attaching it okay once done then only move it to in-review.\"], 'marker': ['Others', 'Others', 'Others', 'Others']}\n",
      "{'text': ['Okay okay dhanuj would be helping Hrisheek in his task yeah', \"Nikita? Yes is she there? Yes yes hey nikita so I actually submitted both the scripts of the week to sarika yesterday itself hmm one on uh Wednesday and second one on Thursday night. So, the latter part is labeling from sarika's side. I have begun my next script next coming week, 4 meeting transcript to be precise. Okay fine uh sravanthi uh yeah let's touch base with sarika i mean 3 of us in a call to understand the i mean the name and the processing yeah yeah \", \"The processess yeah yeah I'll touchbase  I'll connect with you both\", \"Okay sarika is done I thought she's pending. no no sarika already there's some confusion, which I'll talk with talk with her okay got it okay\"], 'marker': ['Collaboration', 'Others', 'Others', 'Others']}\n",
      "{'text': [\"Okay. But what is it you're planning to do for the day?\", 'So actually the UI that I have shown in the start that UI only will be adding more logics oh okay okay', 'yeah 5:30 to 6:30 demo. Yes And the rest of the team can leave. Sarika and Nikita please stay back yeah', 'Oh okay thank you guys bye thank you thank you very much bye good day'], 'marker': ['Action Plan Tracking', 'Others', 'Others', 'Others']}\n",
      "{'text': [\"Perfect then I'll just integrate it all integrate all the codes today\", 'Dhanuj anything pending from your side? No himanshu no. so whatever you have done you have already shared with me. Yeah I have sent you, if you guys shared me on teams or mail? I shared teams you on teams teams okay yeah fine okay Avinash, anything pending from your side? not pending from my not pending anything but uh i need to check how much time it takes for different size of video files ', \"But, uh, the video,uh which I have uploaded is through postman's. So maybe it took long time. Now we are uploading through the website. Okay. \", 'but anyways uploading is still going right ,Anyways it is going from local to server either through website or through so it will take time still'], 'marker': ['Others', 'Others', 'Others', 'Others']}\n",
      "{'text': ['But uh uploading through website is taking less time than uploading through postman', \"task is done, right. And it's getting uploaded. And a, as it is uploaded, it is starting the containers. Uh, speech man container? Hmm correct  And Once it is, once everything is done, are you sending any flag back so that the UI knows that everything is done and the buttons should be activated. yeah \", \"right now I'm sending the oral JSON and and response of that meeting but definitely yeah\", 'we need to know through the this thing so the UI that everything is. So maybe in the JSON that you are generating a can have a flag like ready. So if ready flag will be false still last JSON last uh component of JSON is uploaded at otherwise '], 'marker': ['Others', 'Others', 'Others', 'Others']}\n",
      "{'text': [\"Yes at the starting maybe uh if ready is false that means is still it is getting generated if ready is true, that means now all the generation is done and then UI will know that yeah it's done.\", 'Oh divesh and hrishee uh so I guess you guys are done with the upload part and everything and how about the pending task? So I mean which is coffee or something?', 'the upload file is almost done. So we are trying to some add some 75 components on the to beautify the upload page, with some gifs and some images. Like, Kajari said we need to add some graphic things on. Um, on the entire pipeline so currently we are doing now', 'by end of the day or tomorrow morning it will be done. Perfect so avinash you have that key so we have to think of a '], 'marker': ['Others', 'Others', 'Others', 'Others']}\n",
      "{'text': ['of a scenario where like every minute or every five minutes, a request is sent to, uh, the Mongo DB, API which avinash has created for talking with mongo and it should and we should check that JSON if ready tag ready is false than the button should not be active, if ready is true then button should be active.', 'So that means you and hrisheek both are doing this task. Right? Yes himanshu yeah so what so then I will work on this logic', 'That means by evening, we will have it, right. Yeah yeah okay by evening we will have it. So I will send that request and it will give me true ', 'Um, then I will create, I will download that JSON and I will check for the false tags'], 'marker': ['Others', 'Others', 'Others', 'Others']}\n",
      "{'text': ['Let me know okay? So I have a doubt. So if you add a ready tag so you um what what are you doing? You calling API or mongo DB collection right?', 'Mongo DB I will be calling your API which talks with the mongo DB collection', \"Oh okay so if you call okay so which API you will call? Because thera re 7 or 8 API's\", \"Uh I guess a little bit of frontend is pending okay I have to talk to you regarding this we'll have a call\"], 'marker': ['Others', 'Others', 'Others', 'Others']}\n",
      "{'text': [\"So I am outside so that's why I joined from mobile I will reach home by 2:30 so maybe after that I'll ping you and we'll connect okay?\", 'got it so okay so uh anything else sarika nikita you guys want to add?', \"Sure sure carry on so I will be working on the same labeling of the script which I received so yeah today I'm blocked with that task today yeah um, Himanshu I'm beginning with the second script of a week so I'll be transcribing that today.\", 'Okay yeah yeah suresh anything pending from your side I think everyone is done'], 'marker': ['Others', 'Others', 'Others', 'Others']}\n",
      "{'text': [\"Um, uh, I don't think so himanshu so actually that the last time Nikita had given that feedback icon no so that icon I need to add so that icon I can pass to Amit he can just had it\", 'Wednesday is our demo so today by end of the day.  Most of the things from my side will be complete whatever is pending tomorrow I will integrate', 'Thank you guys so uh whatever you guys have shared I will integrate it today and uh whatever is pending so whatever you guys are doing', \"thank you himanshu thank you himanshu thank you I'm good Thank you himanshu thank you himanshu Bye bye. Thank you. Bye bye\"], 'marker': ['Others', 'Others', 'Others', 'Others']}\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kubeflow",
   "language": "python",
   "name": "kubeflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
